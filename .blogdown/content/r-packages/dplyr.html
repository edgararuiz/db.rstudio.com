---
title: "Using dplyr with databases"
aliases:
  - /dplyr
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>As well as working with local in-memory data stored in data frames, <code>dplyr</code> also works with remote on-disk data stored in databases. This is particularly useful in two scenarios:</p>
<ul>
<li><p>Your data is already in a database.</p></li>
<li><p>You have so much data that it does not all fit into memory simultaneously
and you need to use some external storage engine.</p></li>
</ul>
<p>(If your data fits in memory, there is no advantage to putting it in a database; it will only be slower and more frustrating.)</p>
<p>This vignette focuses on the first scenario because it is the most common. If you are using R to do data analysis inside a company, most of the data you need probably already lives in a database (it’s just a matter of figuring out which one!). However, you will learn how to load data in to a local database in order to demonstrate <code>dplyr</code>’s database tools. At the end, I’ll also give you a few pointers if you do need to set up your own database.</p>
<div id="getting-started" class="section level2">
<h2>Getting started</h2>
<p>To use databases with <code>dplyr</code>, you need to first install <code>dbplyr</code>:</p>
<pre class="r"><code>install.packages(&quot;dbplyr&quot;)</code></pre>
<p>You’ll also need to install a DBI backend package. The <code>DBI</code> package provides a common interface that allows <code>dplyr</code> to work with many different databases using the same code. <code>DBI</code> is automatically installed with <code>dbplyr</code>, but you need to install a specific backend for the database that you want to connect to.</p>
<p>Five commonly used backends are:</p>
<ul>
<li><p><a href="https://github.com/rstats-db/RMySQL#readme">RMySQL</a>
connects to MySQL and MariaDB</p></li>
<li><p><a href="https://CRAN.R-project.org/package=RPostgreSQL">RPostgreSQL</a>
connects to Postgres and Redshift.</p></li>
<li><p><a href="https://github.com/rstats-db/RSQLite">RSQLite</a> embeds a SQLite database.</p></li>
<li><p><a href="https://github.com/rstats-db/odbc#odbc">odbc</a> connects to many commercial
databases via the open database connectivity protocol.</p></li>
<li><p><a href="https://github.com/rstats-db/bigrquery">bigrquery</a> connects to Google’s
BigQuery.</p></li>
</ul>
<p>If the database you need to connect to is not listed here, you’ll need to do some investigation yourself.</p>
<p>In this vignette, we’re going to use the <code>RSQLite</code> backend, which is automatically installed when you install <code>dbplyr</code>. SQLite is a great way to get started with databases because it’s completely embedded inside an R package. Unlike most other systems, you don’t need to set up a separate database server. SQLite is great for demos, but is surprisingly powerful, and with a little practice you can use it to easily work with many gigabytes of data.</p>
</div>
<div id="connecting-to-the-database" class="section level2">
<h2>Connecting to the database</h2>
<p>To work with a database in <code>dplyr</code>, you must first connect to it, using <code>DBI::dbConnect()</code>. We’re not going to go into the details of the <code>DBI</code> package here, but it’s the foundation upon which <code>dbplyr</code> is built. You’ll need to learn more about if you need to do things to the database that are beyond the scope of <code>dplyr</code>.</p>
<pre class="r"><code>library(dplyr)
con &lt;- DBI::dbConnect(RSQLite::SQLite(), path = &quot;:dbname:&quot;)</code></pre>
<p>The arguments to <code>DBI::dbConnect()</code> vary from database to database, but the first argument is always the database backend. It’s <code>RSQLite::SQLite()</code> for RSQLite, <code>RMySQL::MySQL()</code> for RMySQL, <code>RPostgreSQL::PostgreSQL()</code> for RPostgreSQL, <code>odbc::odbc()</code> for odbc, and <code>bigrquery::bigquery()</code> for BigQuery. SQLite only needs one other argument: the path to the database. Here we use the special string, <code>":memory:"</code>, which causes SQLite to make a temporary in-memory database.</p>
<p>Most existing databases don’t live in a file, but instead live on another server. In real life that your code will look more like this:</p>
<pre class="r"><code>con &lt;- DBI::dbConnect(RMySQL::MySQL(), 
  host = &quot;database.rstudio.com&quot;,
  user = &quot;hadley&quot;,
  password = rstudioapi::askForPassword(&quot;Database password&quot;)
)</code></pre>
<p>(If you’re not using RStudio, you’ll need some other way to securely retrieve your password. You should never record it in your analysis scripts or type it into the console.)</p>
<p>Our temporary database has no data in it, so we’ll start by copying over <code>nycflights13::flights</code> using the convenient <code>copy_to()</code> function. This is a quick and dirty way of getting data into a database and is useful primarily for demos and other small jobs.</p>
<pre class="r"><code>copy_to(con, nycflights13::flights, &quot;flights&quot;,
  temporary = FALSE, 
  indexes = list(
    c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), 
    &quot;carrier&quot;, 
    &quot;tailnum&quot;,
    &quot;dest&quot;
  )
)</code></pre>
<p>As you can see, the <code>copy_to()</code> operation has an additional argument that allows you to supply indexes for the table. Here we set up indexes that will allow us to quickly process the data by day, carrier, plane, and destination. Creating the write indices is key to good database performance, but is unfortunately beyond the scope of this article.</p>
<p>Now that we’ve copied the data, we can use <code>tbl()</code> to take a reference to it:</p>
<pre class="r"><code>flights_db &lt;- tbl(con, &quot;flights&quot;)</code></pre>
<p>When you print it out, you’ll notice that it mostly looks like a regular tibble:</p>
<pre class="r"><code>flights_db 
#&gt; # Source:   table&lt;flights&gt; [?? x 19]
#&gt; # Database: sqlite 3.34.1 []
#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;
#&gt; 1  2013     1     1      517            515         2      830            819
#&gt; 2  2013     1     1      533            529         4      850            830
#&gt; 3  2013     1     1      542            540         2      923            850
#&gt; 4  2013     1     1      544            545        -1     1004           1022
#&gt; 5  2013     1     1      554            600        -6      812            837
#&gt; 6  2013     1     1      554            558        -4      740            728
#&gt; # … with more rows, and 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,
#&gt; #   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,
#&gt; #   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dbl&gt;</code></pre>
<p>The main difference is that you can see that it’s a remote source in a SQLite database.</p>
</div>
<div id="generating-queries" class="section level2">
<h2>Generating queries</h2>
<p>To interact with a database you usually use SQL, the Structured Query Language. SQL is over 40 years old, and is used by pretty much every database in existence. The goal of <code>dbplyr</code> is to automatically generate SQL for you so that you’re not forced to use it. However, SQL is a very large language, and <code>dbplyr</code> doesn’t do everything. It focuses on <code>SELECT</code> statements, the SQL you write most often as an analyst.</p>
<p>Most of the time you don’t need to know anything about SQL, and you can continue to use the <code>dplyr</code> verbs that you’re already familiar with:</p>
<pre class="r"><code>flights_db %&gt;% select(year:day, dep_delay, arr_delay)
#&gt; # Source:   lazy query [?? x 5]
#&gt; # Database: sqlite 3.34.1 []
#&gt;    year month   day dep_delay arr_delay
#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;
#&gt; 1  2013     1     1         2        11
#&gt; 2  2013     1     1         4        20
#&gt; 3  2013     1     1         2        33
#&gt; 4  2013     1     1        -1       -18
#&gt; 5  2013     1     1        -6       -25
#&gt; 6  2013     1     1        -4        12
#&gt; # … with more rows

flights_db %&gt;% filter(dep_delay &gt; 240)
#&gt; # Source:   lazy query [?? x 19]
#&gt; # Database: sqlite 3.34.1 []
#&gt;    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time
#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;
#&gt; 1  2013     1     1      848           1835       853     1001           1950
#&gt; 2  2013     1     1     1815           1325       290     2120           1542
#&gt; 3  2013     1     1     1842           1422       260     1958           1535
#&gt; 4  2013     1     1     2115           1700       255     2330           1920
#&gt; 5  2013     1     1     2205           1720       285       46           2040
#&gt; 6  2013     1     1     2343           1724       379      314           1938
#&gt; # … with more rows, and 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,
#&gt; #   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;,
#&gt; #   distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dbl&gt;

flights_db %&gt;% 
  group_by(dest) %&gt;%
  summarise(delay = mean(dep_time))
#&gt; Warning: Missing values are always removed in SQL.
#&gt; Use `mean(x, na.rm = TRUE)` to silence this warning
#&gt; This warning is displayed only once per session.
#&gt; # Source:   lazy query [?? x 2]
#&gt; # Database: sqlite 3.34.1 []
#&gt;   dest  delay
#&gt;   &lt;chr&gt; &lt;dbl&gt;
#&gt; 1 ABQ   2006.
#&gt; 2 ACK   1033.
#&gt; 3 ALB   1627.
#&gt; 4 ANC   1635.
#&gt; 5 ATL   1293.
#&gt; 6 AUS   1521.
#&gt; # … with more rows</code></pre>
<p>However, in the long run, I highly recommend you at least learn the basics of SQL. It’s a valuable skill for any data scientist, and it will help you debug problems if you run into problems with <code>dplyr</code>’s automatic translation. If you’re completely new to SQL, you might start with this <a href="https://www.codecademy.com/learn/learn-sql">codeacademy tutorial</a>. If you have some familiarity with SQL and you’d like to learn more, I found <a href="http://www.sqlite.org/queryplanner.html">how indexes work in SQLite</a> and <a href="http://blog.jooq.org/2016/03/17/10-easy-steps-to-a-complete-understanding-of-sql">10 easy steps to a complete understanding of SQL</a> to be particularly helpful.</p>
<p>The most important difference between ordinary data frames and remote database queries is that your R code is translated into SQL and executed in the database, not in R. When working with databases, <code>dplyr</code> tries to be as lazy as possible:</p>
<ul>
<li><p>It never pulls data into R unless you explicitly ask for it.</p></li>
<li><p>It delays doing any work until the last possible moment: it collects together
everything you want to do and then sends it to the database in one step.</p></li>
</ul>
<p>For example, take the following code:</p>
<pre class="r"><code>tailnum_delay_db &lt;- flights_db %&gt;% 
  group_by(tailnum) %&gt;%
  summarise(
    delay = mean(arr_delay),
    n = n()
  ) %&gt;% 
  arrange(desc(delay)) %&gt;%
  filter(n &gt; 100)</code></pre>
<p>Surprisingly, this sequence of operations never touches the database. It’s not until you ask for the data (e.g., by printing <code>tailnum_delay</code>) that <code>dplyr</code> generates the SQL and requests the results from the database. Even then it tries to do as little work as possible and only pulls down a few rows.</p>
<pre class="r"><code>tailnum_delay_db
#&gt; Warning: ORDER BY is ignored in subqueries without LIMIT
#&gt; ℹ Do you need to move arrange() later in the pipeline or use window_order() instead?
#&gt; # Source:     lazy query [?? x 3]
#&gt; # Database:   sqlite 3.34.1 []
#&gt; # Ordered by: desc(delay)
#&gt;   tailnum delay     n
#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;
#&gt; 1 &lt;NA&gt;    NA     2512
#&gt; 2 N0EGMQ   9.98   371
#&gt; 3 N10156  12.7    153
#&gt; 4 N10575  20.7    289
#&gt; 5 N11106  14.9    129
#&gt; 6 N11107  15.0    148
#&gt; # … with more rows</code></pre>
<p>Behind the scenes, <code>dplyr</code> is translating your R code into SQL. You can see the SQL it’s generating with <code>show_query()</code>:</p>
<pre class="r"><code>tailnum_delay_db %&gt;% show_query()
#&gt; Warning: ORDER BY is ignored in subqueries without LIMIT
#&gt; ℹ Do you need to move arrange() later in the pipeline or use window_order() instead?
#&gt; &lt;SQL&gt;
#&gt; SELECT *
#&gt; FROM (SELECT `tailnum`, AVG(`arr_delay`) AS `delay`, COUNT(*) AS `n`
#&gt; FROM `flights`
#&gt; GROUP BY `tailnum`)
#&gt; WHERE (`n` &gt; 100.0)</code></pre>
<p>If you’re familiar with SQL, this probably isn’t exactly what you’d write by hand, but it does the job. You can learn more about the SQL translation in <code>vignette("sql-translation")</code>.</p>
<p>Typically, you’ll iterate a few times before you figure out what data you need from the database. Once you’ve figured it out, use <code>collect()</code> to pull all the data down into a local tibble:</p>
<pre class="r"><code>tailnum_delay &lt;- tailnum_delay_db %&gt;% collect()
#&gt; Warning: ORDER BY is ignored in subqueries without LIMIT
#&gt; ℹ Do you need to move arrange() later in the pipeline or use window_order() instead?
tailnum_delay
#&gt; # A tibble: 1,201 x 3
#&gt;   tailnum delay     n
#&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;
#&gt; 1 &lt;NA&gt;    NA     2512
#&gt; 2 N0EGMQ   9.98   371
#&gt; 3 N10156  12.7    153
#&gt; 4 N10575  20.7    289
#&gt; 5 N11106  14.9    129
#&gt; 6 N11107  15.0    148
#&gt; # … with 1,195 more rows</code></pre>
<p><code>collect()</code> requires that database does some work, so it may take a long time to complete. Otherwise, <code>dplyr</code> tries to prevent you from accidentally performing expensive query operations:</p>
<ul>
<li><p>Because there’s generally no way to determine how many rows a query will
return unless you actually run it, <code>nrow()</code> is always <code>NA</code>.</p></li>
<li><p>Because you can’t find the last few rows without executing the whole
query, you can’t use <code>tail()</code>.</p></li>
</ul>
<pre class="r"><code>nrow(tailnum_delay_db)
#&gt; [1] NA

tail(tailnum_delay_db)
#&gt; Error: tail() is not supported by sql sources</code></pre>
<p>You can also ask the database how it plans to execute the query with <code>explain()</code>. The output is database-dependent and can be esoteric, but learning a bit about it can be very useful because it helps you understand if the database can execute the query efficiently, or if you need to create new indices.</p>
</div>
<div id="creating-your-own-database" class="section level2">
<h2>Creating your own database</h2>
<p>If you don’t already have a database, here’s some advice from my experiences setting up and running all of them. SQLite is by far the easiest to get started with, but the lack of window functions makes it limited for data analysis. PostgreSQL is not too much harder to use and has a wide range of built-in functions. In my opinion, you shouldn’t bother with MySQL/MariaDB; it’s a pain to set up, the documentation is sub par, and it’s less feature-rich than Postgres. Google BigQuery might be a good fit if you have very large data, or if you’re willing to pay (a small amount of) money to someone who’ll look after your database.</p>
<p>All of these databases follow a client-server model - a computer that connects to the database and the computer that is running the database (the two may be one and the same, but usually aren’t). Getting one of these databases up and running is beyond the scope of this article, but there are plenty of tutorials available on the web.</p>
<div id="mysqlmariadb" class="section level3">
<h3>MySQL/MariaDB</h3>
<p>In terms of functionality, MySQL lies somewhere between SQLite and PostgreSQL. It provides a wider range of <a href="http://dev.mysql.com/doc/refman/5.0/en/functions.html">built-in functions</a>, but it does not support window functions (so you can’t do grouped mutates and filters).</p>
</div>
<div id="postgresql" class="section level3">
<h3>PostgreSQL</h3>
<p>PostgreSQL is a considerably more powerful database than SQLite. It has:</p>
<ul>
<li><p>a much wider range of <a href="http://www.postgresql.org/docs/9.3/static/functions.html">built-in functions</a>, and</p></li>
<li><p>support for <a href="http://www.postgresql.org/docs/9.3/static/tutorial-window.html">window functions</a>, which allow grouped subset and mutates to work.</p></li>
</ul>
</div>
<div id="bigquery" class="section level3">
<h3>BigQuery</h3>
<p>BigQuery is a hosted database server provided by Google. To connect, you need to provide your <code>project</code>, <code>dataset</code> and optionally a project for <code>billing</code> (if billing for <code>project</code> isn’t enabled).</p>
<p>It provides a similar set of functions to Postgres and is designed specifically for analytic workflows. Because it’s a hosted solution, there’s no setup involved, but if you have a lot of data, getting it to Google can be an ordeal (especially because upload support from R is not great currently). (If you have lots of data, you can <a href="https://cloud.google.com/storage/docs/offline-media-import-export">ship hard drives</a>!)</p>
</div>
</div>
